{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Information:\n",
    "\n",
    "### Team Member 1:\n",
    "* UNI: mf3090\n",
    "* Name: Michael Figueroa\n",
    "\n",
    "### Team Member 2 [optional]:\n",
    "* UNI: baa2146\n",
    "* Name: Brett Averso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step0 - Import Libraries, Load Data [0 points]\n",
    "\n",
    "This is the basic step where you can load the data and create train and test sets for internal validation as per your convinience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brettaverso/Desktop/homework-iii-baverso/data\n"
     ]
    }
   ],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write code below, you can make multiple cells\n",
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import Imputer, OneHotEncoder, StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# CHECK P 295 FOR THIS CURVE TUTORIAL\n",
    "from sklearn.metrics import roc_curve "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1 - Exploration and Preparation [10 points]\n",
    "\n",
    "In this step, we expect you to look into the data and try to understand it before modeling. This understanding may lead to some basic data preparation steps which are common across the two model sets required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write code below, you can make multiple cells\n",
    "\n",
    "# NOTE: WE CAN SET NA VALUES HERE TO LOOK AT WHICH ROWS HAVE NA\n",
    "train = pd.read_csv('data.csv', sep=',', na_values=[999, 9999, 99999, 999999, 9999999])\n",
    "test = pd.read_csv('holdout.csv', sep=',')\n",
    "h_ID = test.ID\n",
    "test = test.drop('ID', axis = 1)\n",
    "test.columns\n",
    "# drop duration column (we do not have this information before a new call. we drop to avoid an overly optimistic model)\n",
    "train = train.drop('duration', axis = 1)\n",
    "test = test.drop('duration', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The code is commented out. We originally planned to replace 'unknown' with np.NaN, however decided that\n",
    "# 'unknown' as a categorical value is a sufficient descriptor for classification.\n",
    "#train['job'].replace('unknown', np.NaN, inplace=True)\n",
    "#train['marital_status'].replace('unknown', np.NaN, inplace=True)\n",
    "#train['education'].replace('unknown', np.NaN, inplace=True)\n",
    "#train['credit_default'].replace('unknown', np.NaN, inplace=True)\n",
    "#train['housing'].replace('unknown',np.NaN, inplace=True)\n",
    "#train['loan'].replace('unknown',np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE: Train and validate your model using data.csv and test on holdout.cv\n",
    "\n",
    "# NOTE: SVC is sensitive to scaling\n",
    "\n",
    "# NOTE: random forest n_estimators > 100 main parameter: max_features, set a random state for the random forest\n",
    "\n",
    "# NOTE: Tuning Gradient Boosting: Pick n_estimators, tune learning rate\n",
    "\n",
    "# NOTE: DECISION TREES HAVE A .feaure_importance, but for rf and gbt which are unstable means that feature importances are unstable\n",
    "\n",
    "# NOTE: Linear Models work better if the features are normally distributed\n",
    "\n",
    "# SET THRESHOLDS THAT ALLOW YOU TO SAY HOW MANY FALSE POSITIVE DO WE ALLOW? HOW MANY FALSE NEGATIVES\n",
    "# THINK ABOUT THIS WHEN CREATING A SCORING METRIC\n",
    "# MANY FALSE POSIIVES WILL MEAN THAT OUR CALLER WILL TRY MUCH HARDER AND MAKE MORE PHONE CALLS TO THIS THIS PARTICULAR CLIENT \n",
    "# (THIS MAY MEAN THAT TIME IS WASTED THAT COULD BE SPENT ON ANOTHER CUSTOMER)\n",
    "# MANY FALSE NEGATIVES WILL MEAN THAT WE WILL NOT PAY MUCH ATTENTION TO A CLIENT IN THE FUTURE (THE BANK MAY LOSE MONEY HERE)\n",
    "# HIGH RECALL = AVOIDING FALSE NEGATIVES\n",
    "# HIGH PRECISION = AVOIDING FALSE POSITIVES\n",
    "\n",
    "# NOTE: setting a decision threshold\n",
    "# on the test set is likely to yield overly optimistic results. Use a\n",
    "# validation set or cross-validation instead.\n",
    "\n",
    "# AFTER DECIDING WHICH WE WANT PLOT A PRECISION RECALL CURVE TELLS YOU RECALL VS PRECISION TRADEOFF(POINT HIGHER TO TOP \n",
    "# RIGHT MEANS THE CLASSIFIER IS BETTER)\n",
    "\n",
    "# NOTE: using scoring = 'roc_auc' for selecting hyper parameters such as gamma, is always a good idea for imbalanced datasets\n",
    "# Keep in mind that AUC does not make use of the default threshold,\n",
    "# though, so adjusting the decision threshold might be necessary to obtain useful classification\n",
    "# results from a model with a high AUC.\n",
    "\n",
    "# Consider using imb.learn to do random over sampling since our dataset is unbalanced\n",
    "# Or Consider reweight sampling\n",
    "# Or Consider using SMOTE, all of these need to import imblearn and create a new pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# There are 31707 null values in prev_days (still need to check if there are other missing encodings in other features)\n",
    "train.prev_days.isnull().value_counts() \n",
    "# Therefore dropping this feature\n",
    "train = train.drop('prev_days', axis = 1)\n",
    "test = test.drop('prev_days', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.0    360\n",
      "34.0    345\n",
      "31.0    324\n",
      "37.0    322\n",
      "33.0    306\n",
      "32.0    302\n",
      "30.0    302\n",
      "38.0    295\n",
      "36.0    291\n",
      "40.0    279\n",
      "39.0    264\n",
      "29.0    253\n",
      "43.0    242\n",
      "42.0    222\n",
      "41.0    222\n",
      "45.0    217\n",
      "44.0    217\n",
      "47.0    213\n",
      "28.0    205\n",
      "48.0    198\n",
      "49.0    192\n",
      "46.0    189\n",
      "50.0    178\n",
      "51.0    171\n",
      "27.0    168\n",
      "26.0    167\n",
      "52.0    159\n",
      "55.0    138\n",
      "53.0    135\n",
      "54.0    133\n",
      "       ... \n",
      "63.0     21\n",
      "17.0     19\n",
      "19.0     18\n",
      "66.0     13\n",
      "65.0     11\n",
      "18.0     11\n",
      "69.0     10\n",
      "70.0      9\n",
      "67.0      9\n",
      "68.0      9\n",
      "71.0      8\n",
      "75.0      7\n",
      "72.0      7\n",
      "74.0      6\n",
      "78.0      6\n",
      "79.0      5\n",
      "76.0      5\n",
      "73.0      4\n",
      "80.0      3\n",
      "84.0      3\n",
      "93.0      2\n",
      "77.0      2\n",
      "85.0      2\n",
      "81.0      2\n",
      "82.0      2\n",
      "96.0      1\n",
      "88.0      1\n",
      "86.0      1\n",
      "90.0      1\n",
      "83.0      1\n",
      "Name: age, dtype: int64\n",
      "admin.           2080\n",
      "blue-collar      1846\n",
      "technician       1372\n",
      "services          801\n",
      "management        584\n",
      "retired           330\n",
      "self-employed     281\n",
      "entrepreneur      258\n",
      "housemaid         233\n",
      "unemployed        217\n",
      "student           167\n",
      "unknown            69\n",
      "Name: job, dtype: int64\n",
      "married     4973\n",
      "single      2312\n",
      "divorced     936\n",
      "unknown       17\n",
      "Name: marital_status, dtype: int64\n",
      "university.degree      2408\n",
      "high.school            1935\n",
      "basic.9y               1156\n",
      "professional.course    1089\n",
      "basic.4y                863\n",
      "basic.6y                446\n",
      "unknown                 337\n",
      "illiterate                4\n",
      "Name: education, dtype: int64\n",
      "no         6529\n",
      "unknown    1709\n",
      "Name: credit_default, dtype: int64\n",
      "yes        4400\n",
      "no         3648\n",
      "unknown     190\n",
      "Name: housing, dtype: int64\n",
      "no         6771\n",
      "yes        1277\n",
      "unknown     190\n",
      "Name: loan, dtype: int64\n",
      "cellular     5242\n",
      "telephone    2996\n",
      "Name: contact, dtype: int64\n",
      "may    2753\n",
      "jul    1458\n",
      "aug    1224\n",
      "jun    1046\n",
      "nov     802\n",
      "apr     535\n",
      "oct     178\n",
      "mar     109\n",
      "sep     105\n",
      "dec      28\n",
      "Name: month, dtype: int64\n",
      "mon    1765\n",
      "thu    1678\n",
      "wed    1603\n",
      "fri    1597\n",
      "tue    1595\n",
      "Name: day_of_week, dtype: int64\n",
      "1.0     3349\n",
      "2.0     2112\n",
      "3.0     1181\n",
      "4.0      571\n",
      "5.0      319\n",
      "6.0      215\n",
      "7.0      125\n",
      "8.0       89\n",
      "9.0       62\n",
      "10.0      54\n",
      "11.0      34\n",
      "12.0      28\n",
      "13.0      14\n",
      "14.0      12\n",
      "15.0      10\n",
      "17.0      10\n",
      "21.0       7\n",
      "18.0       7\n",
      "22.0       6\n",
      "19.0       6\n",
      "16.0       5\n",
      "28.0       4\n",
      "24.0       3\n",
      "27.0       3\n",
      "20.0       3\n",
      "25.0       2\n",
      "23.0       2\n",
      "35.0       1\n",
      "33.0       1\n",
      "43.0       1\n",
      "26.0       1\n",
      "36.0       1\n",
      "Name: campaign, dtype: int64\n",
      "0    7140\n",
      "1     891\n",
      "2     148\n",
      "3      46\n",
      "4      12\n",
      "5       1\n",
      "Name: prev_contacts, dtype: int64\n",
      "nonexistent    7140\n",
      "failure         862\n",
      "success         236\n",
      "Name: prev_outcomes, dtype: int64\n",
      " 1.231209    1\n",
      " 1.196778    1\n",
      " 0.996112    1\n",
      " 1.031328    1\n",
      "-1.814110    1\n",
      "-1.874708    1\n",
      "-1.811607    1\n",
      "-1.732257    1\n",
      "-1.239946    1\n",
      " 1.193646    1\n",
      "-2.969285    1\n",
      " 1.390823    1\n",
      "-1.883070    1\n",
      " 1.544149    1\n",
      " 1.479334    1\n",
      "-1.857405    1\n",
      " 1.247590    1\n",
      " 1.195438    1\n",
      "-1.821011    1\n",
      " 1.258416    1\n",
      "-0.098208    1\n",
      "-0.029028    1\n",
      "-1.654932    1\n",
      " 1.256073    1\n",
      " 1.434929    1\n",
      " 1.499914    1\n",
      " 1.127909    1\n",
      " 1.399949    1\n",
      " 1.300413    1\n",
      "-1.798393    1\n",
      "            ..\n",
      " 1.523172    1\n",
      "-1.792028    1\n",
      " 1.550617    1\n",
      " 1.075230    1\n",
      " 1.348858    1\n",
      "-1.784975    1\n",
      "-0.130176    1\n",
      "-2.954247    1\n",
      " 1.387109    1\n",
      " 1.237822    1\n",
      "-1.777271    1\n",
      " 1.298994    1\n",
      "-1.865728    1\n",
      " 1.520041    1\n",
      " 1.140635    1\n",
      " 1.631384    1\n",
      " 1.115122    1\n",
      " 1.383982    1\n",
      " 1.430323    1\n",
      " 1.576326    1\n",
      "-1.663984    1\n",
      " 1.417795    1\n",
      "-1.874140    1\n",
      "-3.320084    1\n",
      " 1.080678    1\n",
      " 1.458449    1\n",
      "-2.678935    1\n",
      " 1.361146    1\n",
      " 1.353604    1\n",
      " 1.378872    1\n",
      "Name: emp_var_rate, dtype: int64\n",
      "93.714316    1\n",
      "93.471811    1\n",
      "93.104242    1\n",
      "93.117894    1\n",
      "95.046960    1\n",
      "93.256029    1\n",
      "91.256295    1\n",
      "94.323674    1\n",
      "91.141358    1\n",
      "92.865872    1\n",
      "94.549439    1\n",
      "93.636415    1\n",
      "94.698434    1\n",
      "92.793666    1\n",
      "94.353516    1\n",
      "91.843100    1\n",
      "93.962467    1\n",
      "94.003904    1\n",
      "93.277682    1\n",
      "94.114300    1\n",
      "92.470614    1\n",
      "93.462244    1\n",
      "92.786182    1\n",
      "95.218157    1\n",
      "93.173970    1\n",
      "95.421620    1\n",
      "92.000712    1\n",
      "95.120028    1\n",
      "96.221311    1\n",
      "94.876949    1\n",
      "            ..\n",
      "93.445146    1\n",
      "93.722064    1\n",
      "94.068743    1\n",
      "93.754708    1\n",
      "95.429124    1\n",
      "93.784492    1\n",
      "94.507742    1\n",
      "94.347124    1\n",
      "93.024148    1\n",
      "95.067741    1\n",
      "94.586035    1\n",
      "94.776976    1\n",
      "94.418374    1\n",
      "92.687617    1\n",
      "91.679276    1\n",
      "91.613736    1\n",
      "92.460892    1\n",
      "92.995304    1\n",
      "92.826819    1\n",
      "90.964470    1\n",
      "94.497151    1\n",
      "93.681301    1\n",
      "96.668972    1\n",
      "94.163293    1\n",
      "95.675569    1\n",
      "93.982350    1\n",
      "94.021058    1\n",
      "93.288278    1\n",
      "93.706237    1\n",
      "93.559161    1\n",
      "Name: cons_price_idx, dtype: int64\n",
      "-46.448096    1\n",
      "-42.450614    1\n",
      "-46.137538    1\n",
      "-35.870897    1\n",
      "-41.987007    1\n",
      "-40.420555    1\n",
      "-36.710934    1\n",
      "-42.161495    1\n",
      "-42.927148    1\n",
      "-42.325541    1\n",
      "-35.140556    1\n",
      "-46.108451    1\n",
      "-42.611947    1\n",
      "-42.314453    1\n",
      "-38.284477    1\n",
      "-36.020944    1\n",
      "-46.018373    1\n",
      "-41.258429    1\n",
      "-42.258624    1\n",
      "-37.947321    1\n",
      "-35.577207    1\n",
      "-36.103113    1\n",
      "-40.830898    1\n",
      "-35.635744    1\n",
      "-35.802569    1\n",
      "-34.646597    1\n",
      "-29.396059    1\n",
      "-41.294003    1\n",
      "-36.006862    1\n",
      "-34.949835    1\n",
      "             ..\n",
      "-42.332979    1\n",
      "-51.072499    1\n",
      "-41.863159    1\n",
      "-39.786542    1\n",
      "-41.672678    1\n",
      "-36.543778    1\n",
      "-46.927582    1\n",
      "-35.902165    1\n",
      "-43.097320    1\n",
      "-43.036120    1\n",
      "-43.051933    1\n",
      "-41.689656    1\n",
      "-42.800090    1\n",
      "-42.313722    1\n",
      "-36.440997    1\n",
      "-49.988909    1\n",
      "-36.617751    1\n",
      "-46.200252    1\n",
      "-46.531409    1\n",
      "-45.135300    1\n",
      "-35.842945    1\n",
      "-35.746807    1\n",
      "-40.816065    1\n",
      "-42.528047    1\n",
      "-42.946784    1\n",
      "-36.280774    1\n",
      "-43.043732    1\n",
      "-31.161661    1\n",
      "-46.318875    1\n",
      "-42.890366    1\n",
      "Name: cons_conf_idx, dtype: int64\n",
      "5.057619    1\n",
      "4.810680    1\n",
      "1.212606    1\n",
      "1.062605    1\n",
      "0.741544    1\n",
      "4.928410    1\n",
      "4.176009    1\n",
      "4.808212    1\n",
      "4.926791    1\n",
      "4.882952    1\n",
      "4.902102    1\n",
      "1.460102    1\n",
      "1.340273    1\n",
      "4.882944    1\n",
      "4.922386    1\n",
      "4.922651    1\n",
      "4.838109    1\n",
      "5.023414    1\n",
      "1.339356    1\n",
      "4.915526    1\n",
      "5.252834    1\n",
      "1.448222    1\n",
      "1.334340    1\n",
      "3.938722    1\n",
      "4.821421    1\n",
      "4.924686    1\n",
      "4.888163    1\n",
      "0.921007    1\n",
      "1.306723    1\n",
      "4.928389    1\n",
      "           ..\n",
      "4.688294    1\n",
      "4.978688    1\n",
      "4.824530    1\n",
      "5.132729    1\n",
      "4.096354    1\n",
      "4.177256    1\n",
      "4.649192    1\n",
      "5.015315    1\n",
      "1.349174    1\n",
      "1.295581    1\n",
      "4.987385    1\n",
      "0.951711    1\n",
      "1.359565    1\n",
      "3.975922    1\n",
      "1.278578    1\n",
      "4.939987    1\n",
      "5.062529    1\n",
      "4.929131    1\n",
      "1.361188    1\n",
      "4.692309    1\n",
      "1.336184    1\n",
      "0.649698    1\n",
      "4.966145    1\n",
      "4.249790    1\n",
      "4.973274    1\n",
      "4.857618    1\n",
      "4.928493    1\n",
      "4.725373    1\n",
      "4.810350    1\n",
      "4.951483    1\n",
      "Name: euribor3m, dtype: int64\n",
      "5229.0    266\n",
      "5228.0    254\n",
      "5226.0    241\n",
      "5230.0    236\n",
      "5227.0    231\n",
      "5225.0    221\n",
      "5231.0    217\n",
      "5232.0    207\n",
      "5224.0    184\n",
      "5193.0    173\n",
      "5191.0    171\n",
      "5192.0    162\n",
      "5223.0    159\n",
      "5190.0    158\n",
      "5194.0    158\n",
      "5195.0    158\n",
      "5233.0    156\n",
      "5234.0    154\n",
      "5100.0    138\n",
      "5099.0    138\n",
      "5098.0    131\n",
      "5097.0    131\n",
      "5222.0    127\n",
      "5096.0    124\n",
      "5196.0    122\n",
      "5189.0    118\n",
      "5197.0    117\n",
      "5198.0    113\n",
      "5188.0    112\n",
      "5101.0    110\n",
      "         ... \n",
      "4985.0      3\n",
      "4998.0      3\n",
      "5083.0      3\n",
      "4970.0      3\n",
      "5112.0      2\n",
      "5212.0      2\n",
      "5063.0      2\n",
      "4984.0      2\n",
      "5245.0      2\n",
      "5029.0      2\n",
      "5208.0      2\n",
      "5065.0      2\n",
      "4982.0      2\n",
      "5211.0      2\n",
      "5177.0      2\n",
      "5176.0      2\n",
      "4981.0      2\n",
      "5038.0      1\n",
      "4975.0      1\n",
      "5169.0      1\n",
      "5210.0      1\n",
      "4979.0      1\n",
      "5114.0      1\n",
      "5243.0      1\n",
      "5209.0      1\n",
      "5116.0      1\n",
      "5214.0      1\n",
      "5175.0      1\n",
      "4973.0      1\n",
      "5031.0      1\n",
      "Name: nr_employed, dtype: int64\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dummy_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bc28378755a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#verifying the existence of any null values other than 'unknown'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdummy_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dummy_train' is not defined"
     ]
    }
   ],
   "source": [
    "# 999 ENCODES MISSING (CHECK FOR OTHERS)\n",
    "for i in list(test):\n",
    "    print(test[i].value_counts())\n",
    "\n",
    "#verifying the existence of any null values other than 'unknown'\n",
    "dummy_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -----%-------\n",
      "no     29238\n",
      "yes     3712\n",
      "Name: subscribed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# we have an imbalanced dataset (~ 10 times more yes classes)\n",
    "print(\" -----%-------\")\n",
    "print(train['subscribed'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pop subscriptions feature from train set, store in target object.\n",
    "target = train.subscribed\n",
    "train = train.drop('subscribed', axis = 1)\n",
    "train.columns\n",
    "\n",
    "#assign binary for no and yes\n",
    "target.replace('no',0, inplace=True)\n",
    "target.replace('yes',1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x110809358>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1101ec198>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x11024d5c0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x110286f98>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x11060e4e0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x110621c88>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x11069d400>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1107a7908>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1107ec080>]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncPh9jxs6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110728c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show histograms of the data for final submission\n",
    "train.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>prev_contacts</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.019059</td>\n",
       "      <td>2.641639</td>\n",
       "      <td>0.174385</td>\n",
       "      <td>0.080115</td>\n",
       "      <td>93.583705</td>\n",
       "      <td>-40.496740</td>\n",
       "      <td>3.618901</td>\n",
       "      <td>5166.932832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.850807</td>\n",
       "      <td>2.803230</td>\n",
       "      <td>0.498989</td>\n",
       "      <td>1.573180</td>\n",
       "      <td>1.162662</td>\n",
       "      <td>4.645301</td>\n",
       "      <td>1.737149</td>\n",
       "      <td>72.439480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.695294</td>\n",
       "      <td>88.311974</td>\n",
       "      <td>-52.220779</td>\n",
       "      <td>0.325461</td>\n",
       "      <td>4963.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.724208</td>\n",
       "      <td>92.800661</td>\n",
       "      <td>-43.087110</td>\n",
       "      <td>1.377065</td>\n",
       "      <td>5101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.085053</td>\n",
       "      <td>93.586959</td>\n",
       "      <td>-41.685507</td>\n",
       "      <td>4.800570</td>\n",
       "      <td>5194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.366367</td>\n",
       "      <td>94.381404</td>\n",
       "      <td>-36.404580</td>\n",
       "      <td>4.943674</td>\n",
       "      <td>5226.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.785673</td>\n",
       "      <td>98.263042</td>\n",
       "      <td>-25.323735</td>\n",
       "      <td>5.362403</td>\n",
       "      <td>5249.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age      campaign  prev_contacts  emp_var_rate  \\\n",
       "count  32950.000000  32950.000000   32950.000000  32950.000000   \n",
       "mean      40.019059      2.641639       0.174385      0.080115   \n",
       "std       10.850807      2.803230       0.498989      1.573180   \n",
       "min       17.000000      1.000000       0.000000     -3.695294   \n",
       "25%       32.000000      1.000000       0.000000     -1.724208   \n",
       "50%       38.000000      2.000000       0.000000      1.085053   \n",
       "75%       47.000000      3.000000       0.000000      1.366367   \n",
       "max       97.000000     56.000000       7.000000      1.785673   \n",
       "\n",
       "       cons_price_idx  cons_conf_idx     euribor3m   nr_employed  \n",
       "count    32950.000000   32950.000000  32950.000000  32950.000000  \n",
       "mean        93.583705     -40.496740      3.618901   5166.932832  \n",
       "std          1.162662       4.645301      1.737149     72.439480  \n",
       "min         88.311974     -52.220779      0.325461   4963.600000  \n",
       "25%         92.800661     -43.087110      1.377065   5101.000000  \n",
       "50%         93.586959     -41.685507      4.800570   5194.000000  \n",
       "75%         94.381404     -36.404580      4.943674   5226.000000  \n",
       "max         98.263042     -25.323735      5.362403   5249.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job',\n",
       " 'marital_status',\n",
       " 'education',\n",
       " 'credit_default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'month',\n",
       " 'day_of_week',\n",
       " 'prev_outcomes']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reviewing the listing of categorical data prior to executing get_dummies\n",
    "categoricals = list(train.select_dtypes(include=['object']))\n",
    "categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The below is commented out as we have chosen to preserve the feature label 'unknown' and not encode with NaN or\n",
    "# impute over it, because per slides, we believe the unknown is an informative value for the model.\n",
    "\n",
    "#imp = Imputer(missing_values='NaN', strategy='most_frequent')\n",
    "#imputed_dummy_train = imp.fit_transform(dummy_train)\n",
    "\n",
    "#imputed_dummy_train = pd.DataFrame(imputed_dummy_train,columns=list(dummy_train))\n",
    "\n",
    "#OHE = OneHotEncoder(categorical_features=categoricals)\n",
    "#impute2 = OHE.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating dummy variables for categorical features\n",
    "dummy_train = pd.get_dummies(train,dummy_na=False)\n",
    "dummy_test = pd.get_dummies(test,dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'credit_default_unknown'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dummy_test)[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_test.insert(34, 'credit_default_yes', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scaling the continuous data\n",
    "continuous_train = dummy_train.select_dtypes(include=['float'])\n",
    "categorical_train = dummy_train.select_dtypes(exclude=['float'])\n",
    "\n",
    "continuous_test = dummy_test.select_dtypes(include=['float'])\n",
    "categorical_test = dummy_test.select_dtypes(exclude=['float'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dummy_train_scaled = scaler.fit_transform(continuous_train)\n",
    "dummy_test_scaled = scaler.fit_transform(continuous_test)\n",
    "dummy_train_scaled = pd.DataFrame(dummy_train_scaled,columns=list(continuous_train))\n",
    "dummy_test_scaled = pd.DataFrame(dummy_test_scaled,columns=list(continuous_test))\n",
    "\n",
    "# Combining continuous and dummy features back into a single train data frame.\n",
    "X_train = pd.concat([dummy_train_scaled, categorical_train],axis=1)\n",
    "X_test = pd.concat([dummy_test_scaled,categorical_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "5        0\n",
       "6        0\n",
       "7        0\n",
       "8        0\n",
       "9        0\n",
       "10       0\n",
       "11       0\n",
       "12       0\n",
       "13       0\n",
       "14       0\n",
       "15       0\n",
       "16       0\n",
       "17       0\n",
       "18       0\n",
       "19       0\n",
       "20       0\n",
       "21       0\n",
       "22       0\n",
       "23       0\n",
       "24       0\n",
       "25       0\n",
       "26       0\n",
       "27       0\n",
       "28       0\n",
       "29       0\n",
       "        ..\n",
       "32920    0\n",
       "32921    0\n",
       "32922    0\n",
       "32923    0\n",
       "32924    0\n",
       "32925    0\n",
       "32926    0\n",
       "32927    0\n",
       "32928    0\n",
       "32929    0\n",
       "32930    0\n",
       "32931    0\n",
       "32932    0\n",
       "32933    0\n",
       "32934    0\n",
       "32935    0\n",
       "32936    0\n",
       "32937    0\n",
       "32938    0\n",
       "32939    0\n",
       "32940    0\n",
       "32941    0\n",
       "32942    0\n",
       "32943    0\n",
       "32944    0\n",
       "32945    0\n",
       "32946    0\n",
       "32947    0\n",
       "32948    0\n",
       "32949    0\n",
       "Name: subscribed, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2 - ModelSet1 [35 points]\n",
    "\n",
    "In this step, we expect you to perform the following steps relevant to the models you choose for set1:\n",
    "\n",
    "* feature engineering\n",
    "* validation\n",
    "* feature selection\n",
    "* final model selection\n",
    "\n",
    "You may select up to 5 models in this step for the purpose of final ensemble. Any classification algorithm covered in class apart from tree-based models can be tested here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.899241433984\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>subscribed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2866</td>\n",
       "      <td>0.031388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1957</td>\n",
       "      <td>0.021497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>768</td>\n",
       "      <td>0.073652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4510</td>\n",
       "      <td>0.019780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7893</td>\n",
       "      <td>0.041529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5540</td>\n",
       "      <td>0.061461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>385</td>\n",
       "      <td>0.181131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5152</td>\n",
       "      <td>0.048427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1770</td>\n",
       "      <td>0.048535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5779</td>\n",
       "      <td>0.036525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4365</td>\n",
       "      <td>0.029735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>917</td>\n",
       "      <td>0.280034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2127</td>\n",
       "      <td>0.396190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2522</td>\n",
       "      <td>0.313949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7039</td>\n",
       "      <td>0.126508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3312</td>\n",
       "      <td>0.061367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5043</td>\n",
       "      <td>0.746994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1087</td>\n",
       "      <td>0.039410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3812</td>\n",
       "      <td>0.025259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6237</td>\n",
       "      <td>0.064266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4125</td>\n",
       "      <td>0.305718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4751</td>\n",
       "      <td>0.074862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2508</td>\n",
       "      <td>0.023207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2753</td>\n",
       "      <td>0.042245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2280</td>\n",
       "      <td>0.247863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5975</td>\n",
       "      <td>0.046310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6328</td>\n",
       "      <td>0.134491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4908</td>\n",
       "      <td>0.067660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1865</td>\n",
       "      <td>0.063042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6535</td>\n",
       "      <td>0.048410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8208</th>\n",
       "      <td>3357</td>\n",
       "      <td>0.049279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8209</th>\n",
       "      <td>5106</td>\n",
       "      <td>0.244388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8210</th>\n",
       "      <td>343</td>\n",
       "      <td>0.762598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8211</th>\n",
       "      <td>7080</td>\n",
       "      <td>0.077528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8212</th>\n",
       "      <td>5908</td>\n",
       "      <td>0.072937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8213</th>\n",
       "      <td>573</td>\n",
       "      <td>0.398890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8214</th>\n",
       "      <td>7178</td>\n",
       "      <td>0.403139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8215</th>\n",
       "      <td>4277</td>\n",
       "      <td>0.038376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8216</th>\n",
       "      <td>3071</td>\n",
       "      <td>0.041250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8217</th>\n",
       "      <td>963</td>\n",
       "      <td>0.091272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8218</th>\n",
       "      <td>812</td>\n",
       "      <td>0.056186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8219</th>\n",
       "      <td>7809</td>\n",
       "      <td>0.046200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8220</th>\n",
       "      <td>819</td>\n",
       "      <td>0.069311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8221</th>\n",
       "      <td>5741</td>\n",
       "      <td>0.037221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8222</th>\n",
       "      <td>5926</td>\n",
       "      <td>0.401821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8223</th>\n",
       "      <td>3194</td>\n",
       "      <td>0.377731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8224</th>\n",
       "      <td>2471</td>\n",
       "      <td>0.373901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8225</th>\n",
       "      <td>1960</td>\n",
       "      <td>0.023251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8226</th>\n",
       "      <td>6292</td>\n",
       "      <td>0.047202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8227</th>\n",
       "      <td>942</td>\n",
       "      <td>0.069278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8228</th>\n",
       "      <td>3660</td>\n",
       "      <td>0.230937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8229</th>\n",
       "      <td>3333</td>\n",
       "      <td>0.039701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8230</th>\n",
       "      <td>6938</td>\n",
       "      <td>0.036150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8231</th>\n",
       "      <td>4213</td>\n",
       "      <td>0.455918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8232</th>\n",
       "      <td>2246</td>\n",
       "      <td>0.054279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8233</th>\n",
       "      <td>4144</td>\n",
       "      <td>0.324528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8234</th>\n",
       "      <td>1269</td>\n",
       "      <td>0.371222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8235</th>\n",
       "      <td>4196</td>\n",
       "      <td>0.074702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8236</th>\n",
       "      <td>2999</td>\n",
       "      <td>0.044474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8237</th>\n",
       "      <td>1642</td>\n",
       "      <td>0.069523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8238 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  subscribed\n",
       "0     2866    0.031388\n",
       "1     1957    0.021497\n",
       "2      768    0.073652\n",
       "3     4510    0.019780\n",
       "4     7893    0.041529\n",
       "5     5540    0.061461\n",
       "6      385    0.181131\n",
       "7     5152    0.048427\n",
       "8     1770    0.048535\n",
       "9     5779    0.036525\n",
       "10    4365    0.029735\n",
       "11     917    0.280034\n",
       "12    2127    0.396190\n",
       "13    2522    0.313949\n",
       "14    7039    0.126508\n",
       "15    3312    0.061367\n",
       "16    5043    0.746994\n",
       "17    1087    0.039410\n",
       "18    3812    0.025259\n",
       "19    6237    0.064266\n",
       "20    4125    0.305718\n",
       "21    4751    0.074862\n",
       "22    2508    0.023207\n",
       "23    2753    0.042245\n",
       "24    2280    0.247863\n",
       "25    5975    0.046310\n",
       "26    6328    0.134491\n",
       "27    4908    0.067660\n",
       "28    1865    0.063042\n",
       "29    6535    0.048410\n",
       "...    ...         ...\n",
       "8208  3357    0.049279\n",
       "8209  5106    0.244388\n",
       "8210   343    0.762598\n",
       "8211  7080    0.077528\n",
       "8212  5908    0.072937\n",
       "8213   573    0.398890\n",
       "8214  7178    0.403139\n",
       "8215  4277    0.038376\n",
       "8216  3071    0.041250\n",
       "8217   963    0.091272\n",
       "8218   812    0.056186\n",
       "8219  7809    0.046200\n",
       "8220   819    0.069311\n",
       "8221  5741    0.037221\n",
       "8222  5926    0.401821\n",
       "8223  3194    0.377731\n",
       "8224  2471    0.373901\n",
       "8225  1960    0.023251\n",
       "8226  6292    0.047202\n",
       "8227   942    0.069278\n",
       "8228  3660    0.230937\n",
       "8229  3333    0.039701\n",
       "8230  6938    0.036150\n",
       "8231  4213    0.455918\n",
       "8232  2246    0.054279\n",
       "8233  4144    0.324528\n",
       "8234  1269    0.371222\n",
       "8235  4196    0.074702\n",
       "8236  2999    0.044474\n",
       "8237  1642    0.069523\n",
       "\n",
       "[8238 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_1(X_train, y_train, X_test):\n",
    "    logit = LogisticRegression()\n",
    "    pipe = make_pipeline(logit)\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "    print(np.mean(scores))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pipe.score(X_train, y_train)\n",
    "    y_prob = pd.concat([h_ID, pd.DataFrame(pipe.predict_proba(X_test)).ix[:,[1]]], axis = 1)\n",
    "    y_prob.columns = ['ID', 'subscribed']\n",
    "    y_prob.to_csv('logistic.csv', index=False)\n",
    "    return y_prob\n",
    "\n",
    "model_1(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3 - ModelSet2 [35 points]\n",
    "\n",
    "In this step, we expect you to perform the following steps relevant to the models you choose for set2:\n",
    "\n",
    "* feature engineering\n",
    "* validation\n",
    "* feature selection\n",
    "* final model selection\n",
    "\n",
    "You may select up to 5 models in this step for the purpose of final ensemble. We encourage you to try decition tree, random forest and gradient boosted tree methods here and pick the one which you think works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write code below, you can make multiple cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4 - Ensemble [20 points + 10 Bonus points]\n",
    "\n",
    "In this step, we expect you to use the models created before and create new predictions. You should definitely try poor man's stacking but we encourage you to think of different ensemble techniques as well. We will judge your creativity and improvement in model performance using ensemble models and you can potentially earn 10 bonus points here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write code below, you can make multiple cells\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "X = X_train\n",
    "y = y_train\n",
    "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "eclf1 = eclf1.fit(X, y)\n",
    "predictions1 = (eclf1.predict(X))\n",
    "eclf2 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft')\n",
    "eclf2 = eclf2.fit(X, y)\n",
    "predictions2 = (eclf2.predict(X))\n",
    "eclf3 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft', weights=[2,1,1])\n",
    "eclf3 = eclf3.fit(X, y)\n",
    "predictions3 = (eclf3.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eclf1.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
